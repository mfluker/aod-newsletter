{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5765a7ce-3c71-4af8-ab15-c237c604278b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating report for 06/16/2025 to 07/16/2025\n",
      "✅ PDF saved: /Users/artofdrawersllc/Documents/Weekly Newsletter Pull/Data/AoD_Weekly_Newsletter_07_16_2025.pdf\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "from urllib.parse import quote_plus\n",
    "from io import StringIO\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import requests\n",
    "from reportlab.lib.pagesizes import LETTER\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DateRange:\n",
    "    \"\"\"Represents a date range with formatting utilities.\"\"\"\n",
    "    start: datetime\n",
    "    end: datetime\n",
    "    \n",
    "    def format(self, fmt: str = \"%m/%d/%Y\") -> Tuple[str, str]:\n",
    "        \"\"\"Format start and end dates.\"\"\"\n",
    "        return self.start.strftime(fmt), self.end.strftime(fmt)\n",
    "    \n",
    "    def get_last_year(self) -> 'DateRange':\n",
    "        \"\"\"Get the same date range from last year.\"\"\"\n",
    "        return DateRange(\n",
    "            start=self.start.replace(year=self.start.year - 1),\n",
    "            end=self.end.replace(year=self.end.year - 1)\n",
    "        )\n",
    "\n",
    "\n",
    "class CanvasSession:\n",
    "    \"\"\"Manages Canvas authentication and session handling.\"\"\"\n",
    "    \n",
    "    COOKIE_PATH = \"canvas_cookies.json\"\n",
    "    BASE_URL = \"https://canvas.artofdrawers.com\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = self._create_session()\n",
    "    \n",
    "    def _create_session(self) -> requests.Session:\n",
    "        \"\"\"Create authenticated session with Canvas cookies.\"\"\"\n",
    "        try:\n",
    "            with open(self.COOKIE_PATH, \"r\") as f:\n",
    "                raw_cookies = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Cookie file not found: {self.COOKIE_PATH}\")\n",
    "        \n",
    "        session = requests.Session()\n",
    "        for cookie in raw_cookies:\n",
    "            params = {\n",
    "                key: cookie[key] for key in [\"domain\", \"path\", \"secure\"] \n",
    "                if key in cookie\n",
    "            }\n",
    "            if \"expirationDate\" in cookie:\n",
    "                params[\"expires\"] = int(cookie[\"expirationDate\"])\n",
    "            \n",
    "            session.cookies.set(\n",
    "                cookie[\"name\"], \n",
    "                cookie[\"value\"], \n",
    "                **params\n",
    "            )\n",
    "        \n",
    "        return session\n",
    "    \n",
    "    def get(self, url: str, **kwargs) -> requests.Response:\n",
    "        \"\"\"Make authenticated GET request.\"\"\"\n",
    "        response = self.session.get(url, **kwargs)\n",
    "        response.raise_for_status()\n",
    "        return response\n",
    "    \n",
    "    def post(self, url: str, **kwargs) -> requests.Response:\n",
    "        \"\"\"Make authenticated POST request.\"\"\"\n",
    "        response = self.session.post(url, **kwargs)\n",
    "        response.raise_for_status()\n",
    "        return response\n",
    "\n",
    "\n",
    "class JobsStatusScraper:\n",
    "    \"\"\"Handles scraping job status data from Canvas.\"\"\"\n",
    "    \n",
    "    STATUS_FILTERS = {\n",
    "        \"Submitted to Manufacturing Partner\": 5,\n",
    "        \"Order Shipped\": 6,\n",
    "    }\n",
    "    \n",
    "    URL_TEMPLATE = \"\"\"\n",
    "    https://canvas.artofdrawers.com/listjobs.html?dsraas=1&id=&location_id=&zone=&zone_id=&production_priority_ge=&production_priority_le=&opportunity=&opportunity_id=&customer=&customer_id=&campaign_source=&customer_id_sub_filters_campaign_source_id=&customer_id_sub_filters_firstname=&customer_id_sub_filters_lastname=&customer_id_sub_filters_spouse=&customer_id_sub_filters_preferred_phone=&customer_id_sub_filters_cell_phone=&customer_id_sub_filters_emailaddr=&city=&state_id=&country_id=&latitude_ge=&latitude_le=&longitude_ge=&longitude_le=&location_tax_rate_id=&total_cost_ge=&total_cost_le=&material_total_ge=&material_total_le=&labor_total_ge=&labor_total_le=&delivery_total_ge=&delivery_total_le=&discount_total_ge=&discount_total_le=&credit_memo_total_ge=&credit_memo_total_le=&tax_total_ge=&tax_total_le=&order_total_ge=&order_total_le=&amount_paid_ge=&amount_paid_le=&amount_due_ge=&amount_due_le=&designer_id=&tma_id=&relationship_partner_id=&installer_id=&shipping_type_id=&number_of_items_ge=&number_of_items_le=&manufacturing_batch_id=&manufacturing_facility_id=&manufacturing_status_id=&date_submitted_to_manufacturing_ge=&date_submitted_to_manufacturing_le=&date_submitted_to_manufacturing_r=select&number_of_days_ago_submitted_to_go_ge=&number_of_days_ago_submitted_to_go_le=&number_of_biz_days_at_manufacturing_status_ge=&number_of_biz_days_at_manufacturing_status_le=&date_submitted_to_manufacturing_partner_ge=&date_submitted_to_manufacturing_partner_le=&date_submitted_to_manufacturing_partner_r=select&date_projected_to_ship_ge=&date_projected_to_ship_le=&date_projected_to_ship_r=select&date_shipped_ge=&date_shipped_le=&date_shipped_r=select&carrier_id=&tracking_number=&date_delivered_ge=&date_delivered_le=&date_delivered_r=select&commission_rate_type_id=&designer_commission_override_percentage_ge=&designer_commission_override_percentage_le=&tma_commission_rate_type_id=&tma_commission_has_been_paid_y=y&tma_commission_has_been_paid_n=n&job_type_id=&current_status_ids%5B%5D=2&current_status_ids%5B%5D=3&current_status_ids%5B%5D=5&current_status_ids%5B%5D=6&current_status_ids%5B%5D=7&current_status_ids%5B%5D=8&current_status_ids%5B%5D=9&current_status_ids%5B%5D=10&current_status_ids%5B%5D=11&current_status_ids%5B%5D=12&current_status_ids%5B%5D=13&current_status_ids%5B%5D=21&current_status_ids%5B%5D=22&current_status_ids%5B%5D=23&current_status_ids%5B%5D=24&current_status_ids%5B%5D=25&current_status_ids%5B%5D=30&current_status_ids%5B%5D=31&current_status_ids%5B%5D=33&current_status_ids%5B%5D=34&current_status_ids%5B%5D=37&current_status_ids%5B%5D=38&date_of_last_status_change_ge=&date_of_last_status_change_le=&date_of_last_status_change_r=select&promotion_id=&date_placed_ge=&date_placed_le=&date_placed_r=select&date_of_initial_appointment_ge=&date_of_initial_appointment_le=&date_of_initial_appointment_r=select&date_of_welcome_call_ge=&date_of_welcome_call_le=&date_of_welcome_call_r=select&date_measurements_scheduled_ge=&date_measurements_scheduled_le=&date_measurements_scheduled_r=select&date_installation_scheduled_ge=&date_installation_scheduled_le=&date_installation_scheduled_r=select&date_of_final_payment_ge=&date_of_final_payment_le=&date_of_final_payment_r=select&date_completed_ge=&date_completed_le=&date_completed_r=select&date_last_payment_ge=&date_last_payment_le=&date_last_payment_r=select&payment_type_id=&memo=&payment_value_lookup=&time_est=&job_survey_response_id=&is_rush_y=y&is_rush_n=n&rush_is_billable_y=y&rush_is_billable_n=n&is_split_order_y=y&is_split_order_n=n&exclude_from_close_rate_y=y&exclude_from_close_rate_n=n&exclude_from_average_sale_y=y&exclude_from_average_sale_n=n&number_of_basics_ge=&number_of_basics_le=&number_of_classics_ge=&number_of_classics_le=&number_of_designers_ge=&number_of_designers_le=&number_of_shelves_ge=&number_of_shelves_le=&number_of_dividers_ge=&number_of_dividers_le=&number_of_accessories_ge=&number_of_accessories_le=&number_of_strip_mounts_ge=&number_of_strip_mounts_le=&number_of_other_ge=&number_of_other_le=&number_of_options_ge=&number_of_options_le=&nps_survey_rating_ge=&nps_survey_rating_le=&wm_note=&active_y=y&date_last_modified_ge=&date_last_modified_le=&date_last_modified_r=select&date_added_ge=&date_added_le=&date_added_r=select&status_field_name_for_filter=REPLACE_STATUS&status_update_search_date_ge=REPLACE_START&status_update_search_date_le=REPLACE_END&status_update_search_date_r=select&sort_by=id&sort_dir=DESC&display=on&c%5B%5D=id&c%5B%5D=location_id&filter=Submit\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    def __init__(self, session: CanvasSession):\n",
    "        self.session = session\n",
    "    \n",
    "    def _build_url(self, status_filter_id: int, date_range: DateRange) -> str:\n",
    "        \"\"\"Build the jobs listing URL with parameters.\"\"\"\n",
    "        start_str, end_str = date_range.format()\n",
    "        return (\n",
    "            self.URL_TEMPLATE\n",
    "            .replace(\"REPLACE_STATUS\", str(status_filter_id))\n",
    "            .replace(\"REPLACE_START\", quote_plus(start_str))\n",
    "            .replace(\"REPLACE_END\", quote_plus(end_str))\n",
    "        )\n",
    "    \n",
    "    def _classify_order_type(self, order_id: str) -> str:\n",
    "        \"\"\"Classify order type based on ID pattern.\"\"\"\n",
    "        if not isinstance(order_id, str):\n",
    "            return \"New\"\n",
    "        \n",
    "        if order_id.startswith(\"C\"):\n",
    "            return \"Claim\"\n",
    "        elif order_id.startswith(\"R\"):\n",
    "            return \"Reorder\"\n",
    "        elif re.match(r\"^\\d\", order_id):\n",
    "            return \"New\"\n",
    "        \n",
    "        return \"New\"\n",
    "    \n",
    "    def _fetch_status_data(self, status_name: str, status_filter_id: int, date_range: DateRange) -> pd.DataFrame:\n",
    "        \"\"\"Fetch and parse job status data.\"\"\"\n",
    "        url = self._build_url(status_filter_id, date_range)\n",
    "        response = self.session.get(url)\n",
    "        \n",
    "        # Clean HTML tags from response\n",
    "        cleaned_text = re.sub(r\"<[^>]+>\", \"\", response.text).strip()\n",
    "        if not cleaned_text:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Parse CSV data\n",
    "        df = pd.read_csv(StringIO(cleaned_text), engine=\"python\")\n",
    "        df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "        \n",
    "        # Find date column\n",
    "        date_column_name = f\"{status_name} Date\".lower()\n",
    "        date_column = next(\n",
    "            (col for col in df.columns if col.lower() == date_column_name), \n",
    "            None\n",
    "        )\n",
    "        \n",
    "        # Add metadata columns\n",
    "        df[\"Status\"] = status_name\n",
    "        df[\"Date\"] = df[date_column] if date_column else pd.NaT\n",
    "        df[\"Order Type\"] = df[\"ID\"].apply(self._classify_order_type)\n",
    "        \n",
    "        return df[[\"ID\", \"Order Type\", \"Franchisee\", \"Date\", \"Status\"]]\n",
    "    \n",
    "    def count_jobs_by_status(self, status_name: str, date_range: DateRange) -> int:\n",
    "        \"\"\"Count jobs in a specific status for a date range.\"\"\"\n",
    "        if status_name not in self.STATUS_FILTERS:\n",
    "            raise ValueError(f\"Unknown status: {status_name}\")\n",
    "        \n",
    "        status_filter_id = self.STATUS_FILTERS[status_name]\n",
    "        df = self._fetch_status_data(status_name, status_filter_id, date_range)\n",
    "        return len(df)\n",
    "    \n",
    "    def generate_combined_csv(self, date_range: DateRange, output_path: Optional[Path] = None) -> pd.DataFrame:\n",
    "        \"\"\"Generate combined CSV of all job statuses.\"\"\"\n",
    "        if output_path is None:\n",
    "            start_str, end_str = date_range.format()\n",
    "            filename = f\"{start_str.replace('/', '')}_{end_str.replace('/', '')}_jobs.csv\"\n",
    "            output_path = Path(\"Data\") / filename\n",
    "        \n",
    "        dataframes = []\n",
    "        for status_name, status_filter_id in self.STATUS_FILTERS.items():\n",
    "            df = self._fetch_status_data(status_name, status_filter_id, date_range)\n",
    "            if not df.empty:\n",
    "                dataframes.append(df)\n",
    "        \n",
    "        if not dataframes:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        combined_df.to_csv(output_path, index=False)\n",
    "        \n",
    "        return combined_df\n",
    "\n",
    "\n",
    "class ConversionReportDownloader:\n",
    "    \"\"\"Handles downloading and processing conversion reports.\"\"\"\n",
    "    \n",
    "    def __init__(self, session: CanvasSession):\n",
    "        self.session = session\n",
    "        self.form_url = f\"{session.BASE_URL}/scripts/lead-to-appointment-conversion/index.html\"\n",
    "        self.csv_url = f\"{session.BASE_URL}/scripts/report_as_spreadsheet.html?report=report_lead_to_appointment_conversion\"\n",
    "    \n",
    "    def download_report(self, date_range: DateRange) -> pd.DataFrame:\n",
    "        \"\"\"Download conversion report for specified date range.\"\"\"\n",
    "        start_str, end_str = date_range.format()\n",
    "        \n",
    "        # Submit form to set parameters\n",
    "        payload = {\n",
    "            \"start_date\": start_str,\n",
    "            \"end_date\": end_str,\n",
    "            \"include_homeshow\": \"true\",\n",
    "            \"quick_search\": \"Search\",\n",
    "            \"search_for\": \"\",\n",
    "            \"submit\": \"Show Report\",\n",
    "        }\n",
    "        \n",
    "        self.session.post(self.form_url, data=payload, headers={\"Referer\": self.form_url})\n",
    "        \n",
    "        # Download CSV data\n",
    "        response = self.session.get(self.csv_url, headers={\"Referer\": self.form_url})\n",
    "        csv_text = response.text\n",
    "        \n",
    "        # Validate response format\n",
    "        if \"Call Center Rep\" not in csv_text.splitlines()[0]:\n",
    "            raise ValueError(f\"Unexpected response format from Canvas: {csv_text[:500]}\")\n",
    "        \n",
    "        # Parse CSV\n",
    "        try:\n",
    "            df = pd.read_csv(StringIO(csv_text))\n",
    "            df[\"Outbound Communication Count\"] = df[\"Outbound Communication Count\"].astype(int)\n",
    "            return df\n",
    "        except pd.errors.ParserError as e:\n",
    "            raise ValueError(f\"Failed to parse CSV: {csv_text[:500]}\") from e\n",
    "    \n",
    "    def get_total_outbound_communications(self, date_range: DateRange) -> int:\n",
    "        \"\"\"Get total outbound communications for date range.\"\"\"\n",
    "        df = self.download_report(date_range)\n",
    "        return df[\"Outbound Communication Count\"].sum()\n",
    "   \n",
    "\n",
    "class PDFReportGenerator:\n",
    "    \"\"\"Generates PDF reports with year-over-year comparisons.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_dir: Path = Path(\"Data\")):\n",
    "        self.output_dir = output_dir\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def _format_yoy_stat(self, label: str, current: float, last_year: float, is_currency: bool = False) -> str:\n",
    "        \"\"\"Format year-over-year statistic with percentage change.\"\"\"\n",
    "        delta = current - last_year\n",
    "        \n",
    "        try:\n",
    "            percent_change = (delta / last_year) * 100\n",
    "        except ZeroDivisionError:\n",
    "            percent_change = 0\n",
    "        \n",
    "        arrow = \"↑\" if percent_change >= 0 else \"↓\"\n",
    "        percent_display = f\"{abs(percent_change):.1f}%\"\n",
    "        \n",
    "        if is_currency:\n",
    "            current_display = f\"${current:,.2f}\"\n",
    "            last_year_display = f\"${last_year:,.2f}\"\n",
    "        else:\n",
    "            current_display = f\"{current:,}\"\n",
    "            last_year_display = f\"{last_year:,}\"\n",
    "        \n",
    "        return f\"<b>{label}:</b> {current_display} ({arrow} {percent_display} vLY) ({last_year_display} LY)\"\n",
    "\n",
    "    def _format_duration_comparison(self, label: str, current_days: float, last_year_days: float) -> str:\n",
    "        \"\"\"\n",
    "        Format an absolute comparison between two durations (in days).\n",
    "        E.g. \"24 days, 20 hours (↑ by 2 days) (22 days, 20 hours LY)\"\n",
    "        \"\"\"\n",
    "        # Human‐readable strings\n",
    "        cur_days = int(current_days)\n",
    "        cur_hours = int((current_days - cur_days) * 24)\n",
    "        ly_days  = int(last_year_days)\n",
    "        ly_hours = int((last_year_days  - ly_days ) * 24)\n",
    "    \n",
    "        # Difference & arrow\n",
    "        diff_days = int(current_days - last_year_days)\n",
    "        arrow     = \"↑\" if diff_days >= 0 else \"↓\"\n",
    "        diff_abs  = abs(diff_days)\n",
    "    \n",
    "        # Build the final line\n",
    "        return (\n",
    "            f\"<b>{label}:</b> \"\n",
    "            f\"{cur_days} days, {cur_hours} hours \"\n",
    "            f\"({arrow} by {diff_abs} days) \"\n",
    "            f\"({ly_days} days, {ly_hours} hours LY)\"\n",
    "        )\n",
    "\n",
    "    \n",
    "    def create_report(self, data: Dict[str, Any], date_range: DateRange, pull_date: str) -> Path:\n",
    "        \"\"\"Create PDF report with provided data.\"\"\"\n",
    "        start_str, end_str = date_range.format()\n",
    "        \n",
    "        # Generate filename\n",
    "        filename = f\"AoD_Weekly_Newsletter_{pull_date.replace('/', '_')}.pdf\"\n",
    "        output_path = self.output_dir / filename\n",
    "        \n",
    "        # Prepare content\n",
    "        styles = getSampleStyleSheet()\n",
    "        story = []\n",
    "        \n",
    "        title = f\"AoD Weekly Newsletter – {pull_date}\"\n",
    "        content_lines = [\n",
    "            title,\n",
    "            \"\",\n",
    "            f\"Data pulled on: {pull_date}\",\n",
    "            f\"Period: {start_str} – {end_str}\",\n",
    "            \"\",\n",
    "            self._format_yoy_stat(\"SSC Touches\", data[\"ssc_current\"], data[\"ssc_last_year\"]),\n",
    "            self._format_yoy_stat(\"Orders Shipped\", data[\"shipped_current\"], data[\"shipped_last_year\"]),\n",
    "            self._format_yoy_stat(\"Orders Submitted\", data[\"submitted_current\"], data[\"submitted_last_year\"]),\n",
    "            self._format_yoy_stat(\"Network Revenue\", data[\"revenue_current\"], data[\"revenue_last_year\"], is_currency=True),\n",
    "            # (\n",
    "            #   f\"<b>Avg. Time From Measurement to Shipped:</b> \"\n",
    "            #   f\"{data['avg_meas_human']} \"\n",
    "            #   f\"({data['avg_meas_diff_arrow']} by {data['avg_meas_diff_days']} days) \"\n",
    "            #   f\"({data['avg_meas_ly_human']} LY)\"\n",
    "            # ),\n",
    "            self._format_duration_comparison(\"Avg. Time From Measurement to Shipped\", data[\"avg_meas_current\"], data[\"avg_meas_lastyr\"]),\n",
    "            \"\",\n",
    "        ]\n",
    "\n",
    "        # if we got a top-3 DataFrame, append it\n",
    "        if \"top3_locations\" in data and isinstance(data[\"top3_locations\"], pd.DataFrame):\n",
    "            top3 = data[\"top3_locations\"]\n",
    "            content_lines.append(\"\")  # blank line\n",
    "            content_lines.append(\"<b>Top 3 Locations by Revenue:</b>\")\n",
    "            for _, row in top3.iterrows():\n",
    "                content_lines.append(f\"{row['Rank']}. {row['Location']} – ${row['Revenue']:,.2f}\")\n",
    "        \n",
    "        # Add content to PDF\n",
    "        for line in content_lines:\n",
    "            story.append(Paragraph(line, styles['Normal']))\n",
    "            story.append(Spacer(1, 12))\n",
    "        \n",
    "        # Build PDF\n",
    "        doc = SimpleDocTemplate(str(output_path), pagesize=LETTER)\n",
    "        doc.build(story)\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "\n",
    "class NetworkRevenue:\n",
    "    \"\"\"Handles downloading and processing network revenue data.\"\"\"\n",
    "    \n",
    "    def __init__(self, session: CanvasSession):\n",
    "        self.session = session\n",
    "        self.report_url = f\"{session.BASE_URL}/scripts/location_sales_rankings.html\"\n",
    "    \n",
    "    def _build_url(self, date_range: DateRange) -> str:\n",
    "        \"\"\"Build URL with date parameters for revenue report.\"\"\"\n",
    "        start_str, end_str = date_range.format()\n",
    "        sd = quote_plus(start_str)\n",
    "        ed = quote_plus(end_str)\n",
    "        return f\"{self.report_url}?sd={sd}&ed={ed}&presetdates=na\"\n",
    "    \n",
    "    def _parse_revenue_table(self, html: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Parse revenue table from HTML response.\"\"\"\n",
    "        try:\n",
    "            from bs4 import BeautifulSoup\n",
    "        except ImportError:\n",
    "            raise ImportError(\"BeautifulSoup4 is required for HTML parsing. Install with: pip install beautifulsoup4\")\n",
    "        \n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        table = soup.find_all(\"table\")[-1]  # Use the last table on the page\n",
    "        \n",
    "        rows = []\n",
    "        total_row = None\n",
    "        \n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cols = tr.find_all(\"td\")\n",
    "            if len(cols) != 3:\n",
    "                continue\n",
    "            \n",
    "            rank, name, revenue = [td.text.strip() for td in cols]\n",
    "            \n",
    "            # Clean revenue value\n",
    "            revenue_clean = float(revenue.replace(\"$\", \"\").replace(\",\", \"\"))\n",
    "            \n",
    "            if name.lower() == \"total\":\n",
    "                total_row = {\n",
    "                    \"Rank\": rank,\n",
    "                    \"Location\": name,\n",
    "                    \"Revenue\": revenue_clean\n",
    "                }\n",
    "            else:\n",
    "                rows.append({\n",
    "                    \"Rank\": int(rank),\n",
    "                    \"Location\": name,\n",
    "                    \"Revenue\": revenue_clean\n",
    "                })\n",
    "        \n",
    "        if total_row is None:\n",
    "            raise ValueError(\"Could not find total row in revenue table.\")\n",
    "        \n",
    "        df_all = pd.DataFrame(rows)\n",
    "        df_top3 = df_all.nlargest(3, \"Revenue\").copy() if not df_all.empty else pd.DataFrame()\n",
    "        df_total = pd.DataFrame([total_row])\n",
    "        \n",
    "        return df_total, df_top3\n",
    "    \n",
    "    def get_revenue_data(self, date_range: DateRange) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Get network revenue data for specified date range.\"\"\"\n",
    "        url = self._build_url(date_range)\n",
    "        response = self.session.get(url)\n",
    "        \n",
    "        return self._parse_revenue_table(response.text)\n",
    "    \n",
    "    def get_total_revenue(self, date_range: DateRange) -> float:\n",
    "        \"\"\"Get total network revenue for date range.\"\"\"\n",
    "        df_total, _ = self.get_revenue_data(date_range)\n",
    "        return df_total.iloc[0][\"Revenue\"]\n",
    "    \n",
    "    def get_revenue_summary(self, date_range: DateRange) -> Tuple[float, pd.DataFrame]:\n",
    "        \"\"\"Get revenue summary with total and top 3 locations.\"\"\"\n",
    "        df_total, df_top3 = self.get_revenue_data(date_range)\n",
    "        total_value = df_total.iloc[0][\"Revenue\"]\n",
    "        return total_value, df_top3\n",
    "\n",
    "\n",
    "class MeasurementShippedScraper:\n",
    "    \n",
    "    URL_TEMPLATE = \"\"\"\n",
    "    https://canvas.artofdrawers.com/listjobs.html?dsraas=1&id=&location_id=&location_id_sub_filters_exclude_from_reports_n=n&zone=&zone_id=&production_priority_ge=&production_priority_le=&opportunity=&opportunity_id=&customer=&customer_id=&campaign_source=&customer_id_sub_filters_campaign_source_id=&customer_id_sub_filters_firstname=&customer_id_sub_filters_lastname=&customer_id_sub_filters_spouse=&customer_id_sub_filters_preferred_phone=&customer_id_sub_filters_cell_phone=&customer_id_sub_filters_emailaddr=&city=&state_id=&country_id=&latitude_ge=&latitude_le=&longitude_ge=&longitude_le=&location_tax_rate_id=&total_cost_ge=&total_cost_le=&material_total_ge=&material_total_le=&labor_total_ge=&labor_total_le=&delivery_total_ge=&delivery_total_le=&discount_total_ge=&discount_total_le=&credit_memo_total_ge=&credit_memo_total_le=&tax_total_ge=&tax_total_le=&order_total_ge=&order_total_le=&amount_paid_ge=&amount_paid_le=&amount_due_ge=&amount_due_le=&siteuser=&designer_id=&tma_id=&relationship_partner_id=&installer_id=&shipping_type_id=&number_of_items_ge=&number_of_items_le=&manufacturing_batch_id=&manufacturing_facility_id=&manufacturing_status_id=&date_submitted_to_manufacturing_ge=&date_submitted_to_manufacturing_le=&date_submitted_to_manufacturing_r=select&number_of_days_ago_submitted_to_go_ge=&number_of_days_ago_submitted_to_go_le=&number_of_biz_days_at_manufacturing_status_ge=&number_of_biz_days_at_manufacturing_status_le=&date_submitted_to_manufacturing_partner_ge=&date_submitted_to_manufacturing_partner_le=&date_submitted_to_manufacturing_partner_r=select&date_projected_to_ship_ge=&date_projected_to_ship_le=&date_projected_to_ship_r=select&date_shipped_ge=REPLACE_START&date_shipped_le=REPLACE_END&date_shipped_r=select&carrier_id=&tracking_number=&date_delivered_ge=&date_delivered_le=&date_delivered_r=select&commission_rate_type_id=&designer_commission_override_percentage_ge=&designer_commission_override_percentage_le=&tma_commission_rate_type_id=&tma_commission_has_been_paid_y=y&tma_commission_has_been_paid_n=n&job_type_id=&%63urrent_status_ids%5B%5D=21&%63urrent_status_ids%5B%5D=22&%63urrent_status_ids%5B%5D=2&%63urrent_status_ids%5B%5D=3&%63urrent_status_ids%5B%5D=23&%63urrent_status_ids%5B%5D=5&%63urrent_status_ids%5B%5D=24&%63urrent_status_ids%5B%5D=33&%63urrent_status_ids%5B%5D=6&%63urrent_status_ids%5B%5D=34&%63urrent_status_ids%5B%5D=37&%63urrent_status_ids%5B%5D=38&%63urrent_status_ids%5B%5D=7&%63urrent_status_ids%5B%5D=8&%63urrent_status_ids%5B%5D=9&%63urrent_status_ids%5B%5D=30&%63urrent_status_ids%5B%5D=10&%63urrent_status_ids%5B%5D=11&%63urrent_status_ids%5B%5D=31&%63urrent_status_ids%5B%5D=25&%63urrent_status_ids%5B%5D=12&%63urrent_status_ids%5B%5D=13&date_of_last_status_change_ge=&date_of_last_status_change_le=&date_of_last_status_change_r=select&promotion_id=&date_placed_ge=&date_placed_le=&date_placed_r=select&date_of_initial_appointment_ge=&date_of_initial_appointment_le=&date_of_initial_appointment_r=select&date_of_welcome_call_ge=&date_of_welcome_call_le=&date_of_welcome_call_r=select&date_measurements_scheduled_ge=&date_measurements_scheduled_le=&date_measurements_scheduled_r=select&date_installation_scheduled_ge=&date_installation_scheduled_le=&date_installation_scheduled_r=select&date_of_final_payment_ge=&date_of_final_payment_le=&date_of_final_payment_r=select&date_completed_ge=&date_completed_le=&date_completed_r=select&date_last_payment_ge=&date_last_payment_le=&date_last_payment_r=select&payment_type_id=&memo=&payment_value_lookup=&time_est=&job_survey_response_id=&is_rush_y=y&is_rush_n=n&rush_is_billable_y=y&rush_is_billable_n=n&is_split_order_y=y&is_split_order_n=n&exclude_from_close_rate_y=y&exclude_from_close_rate_n=n&exclude_from_average_sale_y=y&exclude_from_average_sale_n=n&number_of_basics_ge=&number_of_basics_le=&number_of_classics_ge=&number_of_classics_le=&number_of_designers_ge=&number_of_designers_le=&number_of_shelves_ge=&number_of_shelves_le=&number_of_dividers_ge=&number_of_dividers_le=&number_of_accessories_ge=&number_of_accessories_le=&number_of_strip_mounts_ge=&number_of_strip_mounts_le=&number_of_other_ge=&number_of_other_le=&number_of_options_ge=&number_of_options_le=&nps_survey_rating_ge=&nps_survey_rating_le=&wm_note=&active_y=y&date_last_modified_ge=&date_last_modified_le=&date_last_modified_r=select&date_added_ge=&date_added_le=&date_added_r=select&status_field_name_for_filter=23&status_update_search_date_ge=&status_update_search_date_le=&status_update_search_date_r=inpast&sort_by=id&sort_dir=DESC&c%5B%5D=id&c%5B%5D=location_id&c%5B%5D=order_total&c%5B%5D=date_shipped&filter=Submit\n",
    "    \"\"\".strip()\n",
    "    \n",
    "    def __init__(self, session: CanvasSession):\n",
    "        self.session = session\n",
    "    \n",
    "    def _build_url(self, date_range: DateRange) -> str:\n",
    "        start_str, end_str = date_range.format()\n",
    "        return (\n",
    "            self.URL_TEMPLATE\n",
    "            .replace(\"REPLACE_START\", quote_plus(start_str))\n",
    "            .replace(\"REPLACE_END\",   quote_plus(end_str))\n",
    "        )\n",
    "    \n",
    "    # def measurement_to_shipped(self, date_range: DateRange) -> str:\n",
    "    #     \"\"\"Return average “measurement → shipped” as “X days, Y hours”.\"\"\"\n",
    "    #     # use the session you stored on self\n",
    "    #     resp = self.session.get(self._build_url(date_range))\n",
    "    #     resp.raise_for_status()\n",
    "        \n",
    "    #     # strip tags & read CSV\n",
    "    #     cleaned = re.sub(r\"<[^>]+>\", \"\", resp.text).strip()\n",
    "    #     if not cleaned:\n",
    "    #         return \"No data returned\"\n",
    "    #     df = pd.read_csv(StringIO(cleaned), engine=\"python\")\n",
    "    #     df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "\n",
    "    #     df[\"Date Shipped\"] = pd.to_datetime(df[\"Date Shipped\"], errors=\"coerce\")\n",
    "    #     def parse_last_measurement(s: str) -> pd.Timestamp:\n",
    "    #         if pd.isna(s):\n",
    "    #             return pd.NaT\n",
    "    #         last = s.split(\",\")[-1].strip()\n",
    "    #         return pd.to_datetime(last, errors=\"coerce\")\n",
    "    #     df[\"Measurement Approved Date\"] = df[\"Measurement Approved Date\"].apply(parse_last_measurement)\n",
    "\n",
    "    #     df[\"Days Difference\"] = (\n",
    "    #         (df[\"Date Shipped\"] - df[\"Measurement Approved Date\"])\n",
    "    #         .dt.total_seconds()\n",
    "    #         .div(86400)\n",
    "    #     )\n",
    "    #     valid = df[\"Days Difference\"].dropna()\n",
    "    #     if valid.empty:\n",
    "    #         return \"No valid date pairs to average\"\n",
    "\n",
    "    #     avg = valid.mean()\n",
    "    #     days = int(avg)\n",
    "    #     hours = int((avg - days) * 24)\n",
    "    #     return f\"{days} days, {hours} hours\"\n",
    "\n",
    "    def measurement_to_shipped(self, date_range: DateRange) -> Tuple[float,str]:\n",
    "        \"\"\"\n",
    "        Returns (avg_days_float, human_str) where human_str is\n",
    "        'X days, Y hours'.\n",
    "        \"\"\"\n",
    "        resp = self.session.get(self._build_url(date_range))\n",
    "        resp.raise_for_status()\n",
    "        cleaned = re.sub(r\"<[^>]+>\", \"\", resp.text).strip()\n",
    "        if not cleaned:\n",
    "            return 0.0, \"No data\"\n",
    "        df = pd.read_csv(StringIO(cleaned), engine=\"python\")\n",
    "        df = df.loc[:, ~df.columns.str.contains(\"^Unnamed\")]\n",
    "    \n",
    "        df[\"Date Shipped\"] = pd.to_datetime(df[\"Date Shipped\"], errors=\"coerce\")\n",
    "        df[\"Measurement Approved Date\"] = (\n",
    "            df[\"Measurement Approved Date\"]\n",
    "              .apply(lambda s: pd.to_datetime(s.split(\",\")[-1].strip(), errors=\"coerce\"))\n",
    "        )\n",
    "    \n",
    "        diffs = (\n",
    "            (df[\"Date Shipped\"] - df[\"Measurement Approved Date\"])\n",
    "            .dt.total_seconds()\n",
    "            .div(86400)\n",
    "            .dropna()\n",
    "        )\n",
    "        if diffs.empty:\n",
    "            return 0.0, \"No valid dates\"\n",
    "    \n",
    "        avg = diffs.mean()\n",
    "        days = int(avg)\n",
    "        hours = int((avg - days) * 24)\n",
    "        human = f\"{days} days, {hours} hours\"\n",
    "        \n",
    "        return avg, human\n",
    "\n",
    "\n",
    "\n",
    "class WeeklyReportGenerator:\n",
    "    \"\"\"Main orchestrator for generating weekly reports.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = CanvasSession()\n",
    "        self.jobs_scraper = JobsStatusScraper(self.session)\n",
    "        self.conversion_downloader = ConversionReportDownloader(self.session)\n",
    "        self.network_revenue = NetworkRevenue(self.session)\n",
    "        self.meas_shipped_scraper  = MeasurementShippedScraper(self.session)\n",
    "        self.pdf_generator = PDFReportGenerator()\n",
    "    \n",
    "    def generate_report(self, days_back: int = 30) -> Path:\n",
    "        \"\"\"Generate complete weekly report.\"\"\"\n",
    "        # Setup date ranges\n",
    "        eastern = pytz.timezone(\"US/Eastern\")\n",
    "        today = datetime.now(eastern).date()\n",
    "        \n",
    "        current_range = DateRange(\n",
    "            start=today - timedelta(days=days_back),\n",
    "            end=today\n",
    "        )\n",
    "        last_year_range = current_range.get_last_year()\n",
    "        \n",
    "        pull_date_str = today.strftime(\"%m/%d/%Y\")\n",
    "        \n",
    "        print(f\"Generating report for {current_range.format()[0]} to {current_range.format()[1]}\")\n",
    "\n",
    "        # 1) revenue\n",
    "        revenue_current, top3_df   = self.network_revenue.get_revenue_summary(current_range)\n",
    "        revenue_last_year, _       = self.network_revenue.get_revenue_summary(last_year_range)\n",
    "\n",
    "        # 2) measurement→shipped\n",
    "        avg_cur, avg_cur_str       = self.meas_shipped_scraper.measurement_to_shipped(current_range)\n",
    "        avg_ly,  avg_ly_str        = self.meas_shipped_scraper.measurement_to_shipped(last_year_range)\n",
    "\n",
    "        # Collect all data\n",
    "        data = {\n",
    "            # SSC Touches\n",
    "            \"ssc_current\": self.conversion_downloader.get_total_outbound_communications(current_range),\n",
    "            \"ssc_last_year\": self.conversion_downloader.get_total_outbound_communications(last_year_range),\n",
    "            \n",
    "            # Orders Shipped\n",
    "            \"shipped_current\": self.jobs_scraper.count_jobs_by_status(\"Order Shipped\", current_range),\n",
    "            \"shipped_last_year\": self.jobs_scraper.count_jobs_by_status(\"Order Shipped\", last_year_range),\n",
    "            \n",
    "            # Orders Submitted\n",
    "            \"submitted_current\": self.jobs_scraper.count_jobs_by_status(\"Submitted to Manufacturing Partner\", current_range),\n",
    "            \"submitted_last_year\": self.jobs_scraper.count_jobs_by_status(\"Submitted to Manufacturing Partner\", last_year_range),\n",
    "\n",
    "            # Network Revenue\n",
    "            \"revenue_current\":   revenue_current,\n",
    "            \"revenue_last_year\": revenue_last_year,\n",
    "\n",
    "            # NEW metrics:\n",
    "            \"avg_meas_current\": avg_cur,\n",
    "            \"avg_meas_lastyr\":  avg_ly,\n",
    "\n",
    "            # now include the top-3 locations DataFrame\n",
    "            \"top3_locations\": top3_df,\n",
    "\n",
    "        }\n",
    "        \n",
    "        # Generate PDF\n",
    "        output_path = self.pdf_generator.create_report(data, current_range, pull_date_str)\n",
    "        \n",
    "        print(f\"✅ PDF saved: {output_path.resolve()}\")\n",
    "        return output_path\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    generator = WeeklyReportGenerator()\n",
    "    generator.generate_report()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f3ef6-ad14-4f25-a3a8-36c8d7bf8f16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
